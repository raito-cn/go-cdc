# CDC 全量抓取优化方案

## 1️⃣ 初始化

1. 获取需要同步的表列表
2. 过滤不需要同步的 Schema
3. 发送所有表的建表 DDL 到下游（包含列信息、主键等元数据）
4. 记录全局起始 GTID / binlog position，作为全量抓取基准

---

## 2️⃣ 表级事务快照抓取

对每张表单独进行：

1. 开启可重复读事务;
2. 查询表当前事务快照数据，同时获取该表事务对应的 GTID (`tableGTID`)
    - 表级 GTID 用于增量同步判定
3. 将表数据按 **主键/ID 分块**（chunk）批量抓取
    - 默认分块大小 1000 条，可根据表大小调整

---

## 3️⃣ 分块抓取 & 并发优化

1. 每个 chunk 单独查询、生成 Event
2. Event 直接发送到下游异步队列（如 RabbitMQ/Kafka）
3. 全量抓取期间 **不处理 binlog**
4. 可使用协程并发抓取不同表或同表不同 chunk，提高吞吐量
5. 分块抓取完成后 **更新表级元数据 GTID (`tableGTID`)**
    - 表示该表全量抓取结束
    - 增量 binlog 只处理大于该 GTID 的事件

---

## 4️⃣ 全量抓取结束

1. 等待所有表的全量抓取完成
2. 记录全局全量结束 GTID (`Gfinal`)
3. 发送全量完成 ACK 到下游，通知全量阶段结束

---

## 5️⃣ 增量 binlog 同步

1. 启动 binlog 增量读取
2. 对每个 binlog 事件：
    - 判断事件对应的表
    - 判断事件 GTID 是否大于该表的 `tableGTID`
        - **大于**：处理事件，生成 Event 发送到下游
        - **小于等于**：忽略（属于全量抓取期间已捕获数据）
3. 持续处理后续 binlog，实现全量之后增量同步

---

## 6️⃣ 核心优势

- **保证全量抓取期间的数据完整性**
    - 全量抓取期间的 binlog 写入不会覆盖已抓取数据
- **表级 GTID 管理**
    - 每张表独立维护 GTID，增量判定精确
- **支持大表并发抓取**
    - 分块 + 协程分页抓取，提高吞吐，降低内存压力
- **逻辑简单可扩展**
    - 下游无需做幂等处理
    - 可按表/分块顺序控制抓取策略
- **可恢复性**
    - 失败可从每表已完成 chunk 的 `tableGTID` 继续抓取
    - 全量完成后再增量，增量 GTID 从 `tableGTID` 继续

---

## 7️⃣ 可选优化

- **全量抓取期间的 binlog 缓存**
    - 对于写入非常高的系统，可在全量抓取时缓存 binlog，抓取完成后合并
- **动态分块大小**
    - 根据表大小或并发抓取压力调整 chunk 大小
- **增量事件排序**
    - 对下游要求严格顺序时，可加序号或按 GTID 排序  